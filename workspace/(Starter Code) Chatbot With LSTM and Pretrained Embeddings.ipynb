{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pJAWnBFlkE2w"
   },
   "source": [
    "# LSTM Bot\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "In this project, you will build a chatbot that can converse with you at the command line. The chatbot will use a Sequence to Sequence text generation architecture with an LSTM as it's memory unit. You will also learn to use pretrained word embeddings to improve the performance of the model. At the conclusion of the project, you will be able to show your chatbot to potential employers.\n",
    "\n",
    "Additionally, you have the option to use pretrained word embeddings in your model. We have loaded Brown Embeddings from Gensim in the starter code below. You can compare the performance of your model with pre-trained embeddings against a model without the embeddings.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "A sequence to sequence model (Seq2Seq) has two components:\n",
    "- An Encoder consisting of an embedding layer and LSTM unit.\n",
    "- A Decoder consisting of an embedding layer, LSTM unit, and linear output unit.\n",
    "\n",
    "The Seq2Seq model works by accepting an input into the Encoder, passing the hidden state from the Encoder to the Decoder, which the Decoder uses to output a series of token predictions.\n",
    "\n",
    "## Dependencies\n",
    "\n",
    "- Pytorch\n",
    "- Numpy\n",
    "- Pandas\n",
    "- NLTK\n",
    "- Gzip\n",
    "- Gensim\n",
    "\n",
    "\n",
    "Please choose a dataset from the Torchtext website. We recommend looking at the Squad dataset first. Here is a link to the website where you can view your options:\n",
    "\n",
    "- https://pytorch.org/text/stable/datasets.html\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = False\n",
    "init = False\n",
    "\n",
    "if test:\n",
    "    !pip install -U  pytest\n",
    "if init:\n",
    "    pass\n",
    "    #!pip install torchsummary\n",
    "    #!pip install typing-extensions --upgrade\n",
    "    #!pip install -U torch torchvision torchtext torchdata pytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# public libraries\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gzip\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import torch.optim\n",
    "import random\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# my libraries\n",
    "import src.utils\n",
    "import src.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Proof-of-Concept dataset\n",
    "df_names = pd.read_csv('data/names.csv')\n",
    "\n",
    "poc_questions = []\n",
    "poc_answers = []\n",
    "for i, row in list(df_names.iterrows())[:90]:\n",
    "    poc_questions.append(\"What is your name?\")\n",
    "    name = row[\"First Name\"]+\" \"+row[\"Last Name\"]\n",
    "    poc_answers.append(f\"['My name is {name}]'\")\n",
    "for i, row in list(df_names.iterrows())[90:]:\n",
    "    poc_questions.append(\"What is your name?\")\n",
    "    name = row[\"First Name\"]+\" \"+row[\"Last Name\"]\n",
    "    poc_answers.append(f\"['{name}']\")\n",
    "for i in range(100):\n",
    "    poc_questions.append(\"What is your name?\")\n",
    "    one = random.randint(0,99)\n",
    "    two = random.randint(0,99)\n",
    "    name_one = df_names[\"First Name\"].iloc[one]+\" \"+df_names[\"Last Name\"].iloc[two]\n",
    "    name_two = df_names[\"First Name\"].iloc[two]+\" \"+df_names[\"Last Name\"].iloc[two]\n",
    "    poc_answers.append(f\"['Our name is {name_one} and {name_two}']\")\n",
    "for i, row in list(df_names.iterrows()):\n",
    "    poc_questions.append(\"What is her name?\")\n",
    "    name = row[\"First Name\"]+\" \"+row[\"Last Name\"]\n",
    "    if row[\"Gender\"] == \"Female\":\n",
    "        poc_answers.append(f\"['Her name is {name}']\")\n",
    "for i, row in list(df_names.iterrows()):\n",
    "    poc_questions.append(\"What is his name?\")\n",
    "    name = row[\"First Name\"]+\" \"+row[\"Last Name\"]\n",
    "    if row[\"Gender\"] == \"Male\":\n",
    "        poc_answers.append(f\"['His name is {name}']'\")\n",
    "df_poc = pd.DataFrame(list(zip(poc_questions, poc_answers)),\n",
    "               columns =['question', 'answer'])\n",
    "df_poc.to_csv('data/poc_data.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eg81uNTWixbi",
    "outputId": "9c0f9eda-75fb-4526-e9b6-f9a76eeeb007"
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    from nltk.corpus import brown\n",
    "    from nltk.tokenize import RegexpTokenizer\n",
    "    import gensim\n",
    "\n",
    "\n",
    "    #from ntlk.stem import *\n",
    "\n",
    "    nltk.download('brown')\n",
    "    nltk.download('punkt')\n",
    "\n",
    "    # Output, save, and load brown embeddings\n",
    "\n",
    "    model = gensim.models.Word2Vec(brown.sents())\n",
    "    model.save('brown.embedding')\n",
    "\n",
    "    w2v = gensim.models.Word2Vec.load('brown.embedding')\n",
    "\n",
    "\n",
    "\n",
    "    def loadDF(path):\n",
    "      '''\n",
    "\n",
    "      You will use this function to load the dataset into a Pandas Dataframe for processing.\n",
    "\n",
    "      '''\n",
    "      return df\n",
    "\n",
    "\n",
    "    def prepare_text(sentence):\n",
    "\n",
    "        '''\n",
    "\n",
    "        Our text needs to be cleaned with a tokenizer. This function will perform that task.\n",
    "        https://www.nltk.org/api/nltk.tokenize.html\n",
    "\n",
    "        '''\n",
    "\n",
    "        return tokens\n",
    "\n",
    "\n",
    "\n",
    "    def train_test_split(SRC, TRG):\n",
    "\n",
    "        '''\n",
    "        Input: SRC, our list of questions from the dataset\n",
    "                TRG, our list of responses from the dataset\n",
    "\n",
    "        Output: Training and test datasets for SRC & TRG\n",
    "\n",
    "        '''\n",
    "        share = 0.2\n",
    "        src_split = len(SRC)*share\n",
    "        trg_split = len(TRG)*share\n",
    "        SRC_test_dataset = SRC[:scr_split]\n",
    "        SRC_train_dataset = SRC[scr_split:]\n",
    "        TRG_test_dataset = SRC[:trg_split]\n",
    "        TRG_train_dataset = SRC[trg_split:]\n",
    "\n",
    "\n",
    "        return SRC_train_dataset, SRC_test_dataset, TRG_train_dataset, TRG_test_dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get and watch the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87599 training samples and 10570 have been loaded.\n",
      "The test data makes 89.2% of all the data.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>answer_start</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>To whom did the Virgin Mary allegedly appear i...</td>\n",
       "      <td>['Saint Bernadette Soubirous']</td>\n",
       "      <td>[515]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What is in front of the Notre Dame Main Building?</td>\n",
       "      <td>['a copper statue of Christ']</td>\n",
       "      <td>[188]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>The Basilica of the Sacred heart at Notre Dame...</td>\n",
       "      <td>['the Main Building']</td>\n",
       "      <td>[279]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What is the Grotto at Notre Dame?</td>\n",
       "      <td>['a Marian place of prayer and reflection']</td>\n",
       "      <td>[381]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What sits on top of the Main Building at Notre...</td>\n",
       "      <td>['a golden statue of the Virgin Mary']</td>\n",
       "      <td>[92]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                            context  \\\n",
       "0           0  Architecturally, the school has a Catholic cha...   \n",
       "1           1  Architecturally, the school has a Catholic cha...   \n",
       "2           2  Architecturally, the school has a Catholic cha...   \n",
       "3           3  Architecturally, the school has a Catholic cha...   \n",
       "4           4  Architecturally, the school has a Catholic cha...   \n",
       "\n",
       "                                            question  \\\n",
       "0  To whom did the Virgin Mary allegedly appear i...   \n",
       "1  What is in front of the Notre Dame Main Building?   \n",
       "2  The Basilica of the Sacred heart at Notre Dame...   \n",
       "3                  What is the Grotto at Notre Dame?   \n",
       "4  What sits on top of the Main Building at Notre...   \n",
       "\n",
       "                                        answer answer_start  \n",
       "0               ['Saint Bernadette Soubirous']        [515]  \n",
       "1                ['a copper statue of Christ']        [188]  \n",
       "2                        ['the Main Building']        [279]  \n",
       "3  ['a Marian place of prayer and reflection']        [381]  \n",
       "4       ['a golden statue of the Virgin Mary']         [92]  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if init:\n",
    "    data.squad1_to_csv()\n",
    "    \n",
    "df_train = pd.read_csv('data/train_dataset_squad1.csv')  \n",
    "# df_train = pd.read_csv('data/poc_data.csv')  \n",
    "df_test = pd.read_csv('data/dev_dataset_squad1.csv') \n",
    "# df_test = pd.read_csv('data/poc_data.csv')\n",
    "split = round(len(df_train)*100/(len(df_train)+len(df_test)),1)\n",
    "print(f\"{len(df_train)} training samples and {len(df_test)} have been loaded.\")\n",
    "print(f\"The test data makes {split}% of all the data.\")\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_prep = src.utils.Vocab(name='prepration')\n",
    "raw_questions = [vocab_prep.clean_text(s) for s in df_train[\"question\"].values.tolist()]\n",
    "raw_answers = [vocab_prep.clean_text(q[2:-2]) for q in df_train[\"answer\"].values.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.6140e+03, 2.9118e+04, 3.6943e+04, 1.4995e+04, 3.8720e+03,\n",
       "        8.2300e+02, 1.7400e+02, 4.7000e+01, 1.0000e+01, 3.0000e+00]),\n",
       " array([ 1. ,  4.9,  8.8, 12.7, 16.6, 20.5, 24.4, 28.3, 32.2, 36.1, 40. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Source Data\n",
    "plt.title(\"Distribution of lengths of questions\")\n",
    "plt.hist(np.array([len(n) for n in raw_questions]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([7.1253e+04, 1.0344e+04, 3.0790e+03, 1.7480e+03, 6.9000e+02,\n",
       "        3.9300e+02, 9.0000e+01, 1.0000e+00, 0.0000e+00, 1.0000e+00]),\n",
       " array([ 0. ,  4.3,  8.6, 12.9, 17.2, 21.5, 25.8, 30.1, 34.4, 38.7, 43. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Target Data\n",
    "plt.title(\"Distribution of lengths of answers\")\n",
    "plt.hist(np.array([len(n) for n in raw_answers]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering out of noise\n",
    "\n",
    "I remove all questions with less than 25 words and all answers with less than 13 words (together with their counterpart)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have removed 3.6% of the data.\n"
     ]
    }
   ],
   "source": [
    "index_a = [index for index, row in enumerate(raw_questions) if len(row) < 25]\n",
    "index_b = [index for index, row in enumerate(raw_answers) if len(row) < 13]\n",
    "\n",
    "index_all=list(set(index_a).intersection(set(index_b)))\n",
    "share = round(((len(df_train)-len(index_all))/len(df_train))*100,1)\n",
    "df_train_filtered = df_train.iloc[index_all]\n",
    "print(f\"We have removed {share}% of the data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have to repeat this step with the filtered dataframe\n",
    "raw_questions = [vocab_prep.clean_text(s) for s in df_train_filtered[\"question\"].values.tolist()]\n",
    "raw_answers = [vocab_prep.clean_text(q[2:-2]) for q in df_train_filtered[\"answer\"].values.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The source sequence has to have a length of 26. And the target sequence has to have a length of 13.\n"
     ]
    }
   ],
   "source": [
    "sequence_length_source = src.utils.get_max_length(raw_questions) + 2\n",
    "sequence_length_target = src.utils.get_max_length(raw_answers) + 1\n",
    "print(f\"The source sequence has to have a length of {sequence_length_source}. And the target sequence has to have a length of {sequence_length_target}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source: 41290 target: 40330 common words: 23332\n"
     ]
    }
   ],
   "source": [
    "vocab_source = src.utils.Vocab(name='source')\n",
    "vocab_target = src.utils.Vocab(name='target')\n",
    "\n",
    "count = 0\n",
    "for q, a in zip(raw_questions, raw_answers):\n",
    "\n",
    "    PAD = \"<PAD>\"\n",
    "    SOS = \"<SOS>\"\n",
    "    EOS = \"<EOS>\"\n",
    "    OUT = \"<OUT>\"\n",
    "    special_tokens = [\"<PAD>\", \"<SOS>\", \"<EOS>\", \"<OUT>\"]\n",
    "    for word in special_tokens + q:\n",
    "        vocab_source.indexWord(word)\n",
    "    for word in special_tokens + a:\n",
    "        vocab_target.indexWord(word)\n",
    "\n",
    "print(\"source:\", len(vocab_source.words), \"target:\", len(vocab_target.words), \"common words:\", len(list(set(vocab_source.words.keys()).intersection(set(vocab_target.words.keys())))))\n",
    "\n",
    "questions = src.utils.tokenize_questions(raw_questions, vocab_source)\n",
    "answers = src.utils.tokenize_answers(raw_answers, vocab_target)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if test:\n",
    "    !python -m pytest -vv tests.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "oQLTP2Wmi1eB"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class Encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        \n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        # self.embedding provides a vector representation of the inputs to our model\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        \n",
    "        # self.lstm, accepts the vectorized input and passes a hidden state\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size)\n",
    "        self.dropout = nn.Dropout(p=0.0)\n",
    "        \n",
    "    \n",
    "    def forward(self, i, h):\n",
    "        \n",
    "        '''\n",
    "        Inputs: i, the src vector\n",
    "        Outputs: o, the encoder outputs\n",
    "                h, the hidden state (actually a tuple of hidden state and cell state)\n",
    "        '''\n",
    "        embedding = self.embedding(i)\n",
    "        x,y = h\n",
    "        o, h= self.lstm(embedding, h)\n",
    "        o = self.dropout(o)\n",
    "        \n",
    "        return o, h\n",
    "    \n",
    "\n",
    "class Decoder(nn.Module):\n",
    "      \n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        \n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        # self.embedding provides a vector representation of the target to our model\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        \n",
    "        # self.lstm, accepts the embeddings and outputs a hidden state\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size)\n",
    "\n",
    "        # self.ouput, predicts on the hidden state via a linear output layer  \n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, i, h):\n",
    "        \n",
    "        '''\n",
    "        Inputs: i, the target vector\n",
    "        Outputs: o, the decoder output\n",
    "                h, the hidden state (actually a tuple of hidden state and cell state)\n",
    "        '''\n",
    "\n",
    "        embedding = self.embedding(i)\n",
    "\n",
    "        o, h = self.lstm(embedding, h)\n",
    "\n",
    "        o = self.linear(o)\n",
    "\n",
    "        o = self.softmax(o)\n",
    "\n",
    "        \n",
    "        return o, h\n",
    "        \n",
    "        \n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        \n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = Encoder(input_size, hidden_size)\n",
    "        self.decoder = Decoder(hidden_size, output_size)\n",
    "                \n",
    "        \n",
    "    \n",
    "    \n",
    "    def forward(self, src, trg, start, teacher_forcing_ratio = 0.5): \n",
    "        '''\n",
    "        Inputs: src, the source vector\n",
    "                trg, the target vector\n",
    "        Outputs: o, the prediction\n",
    "                \n",
    "        '''\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        src.to(device)\n",
    "        trg.to(device)\n",
    "        start.to(device)\n",
    "        \n",
    "            \n",
    "        \n",
    "        # encoder\n",
    "        hidden = (torch.zeros(1,hidden_size).to(device), torch.zeros(1,hidden_size).to(device))\n",
    "        for word in src:\n",
    "            #print(\"word\",word.shape,word)\n",
    "            o, hidden = self.encoder(word.view(-1).to(device), hidden)\n",
    "        \n",
    "        # decoder\n",
    "        o = start\n",
    "        \n",
    "        prediction = []\n",
    "        for word in trg:\n",
    "            #print(\"o\", o)\n",
    "            #print(\"o.view(-1)\",o.view(-1))\n",
    "            o, hidden = self.decoder(o.view(-1).to(device), hidden)\n",
    "            prediction.append(o)\n",
    "\n",
    "            if self.training:\n",
    "                o = word if random.random() < teacher_forcing_ratio else torch.argmax(o,dim=1)\n",
    "            else:\n",
    "                o = torch.argmax(o,dim=1)\n",
    "            \n",
    "\n",
    "            \n",
    "        \n",
    "        return torch.stack(prediction).squeeze(1)\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(raw_answers)\n",
    "questions = src.utils.tokenize_questions(raw_questions, vocab_source)\n",
    "answers = src.utils.tokenize_answers(raw_answers, vocab_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([84453, 13])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2640\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "loader = DataLoader(list(zip(raw_questions, raw_answers)), shuffle = False, batch_size = batch_size)\n",
    "print(len(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is cuda: True\n",
      "loading from checkpoint: ''checkpoints/model_1.pt'\n",
      " \n",
      "epoch 0 batch# 0 batch loss: -2.329357948838151e-05 1.9% samples processed\n",
      "question <SOS> In what year was the Joan B Kroc Institute for International Peace Studies founded <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
      "answer: 1986 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
      "prediction: Hochbunker Isidore mistake billion Mahbub Nancy Postes Postes Postes heads employment ParkScore scream \n",
      " \n",
      "epoch 0 batch# 50 batch loss: -2.3327382280058373e-05 3.8% samples processed\n",
      "question <SOS> What year did Chopin s sister Emilia die <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
      "answer: 1827 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
      "prediction: Hochbunker renouncing dynamic Thapa heads heads employment heads 143 1968 ammattikorkeakoulus kingdoms kingdoms \n",
      " \n",
      "epoch 0 batch# 100 batch loss: -2.3018660783691303e-05 5.7% samples processed\n",
      "question <SOS> How much money did Spectre make in its first weekend in the US and Canada <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
      "answer: 70 4 million <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
      "prediction: Hochbunker Eton BeiDou Claudio diversify Spain Vienna heads heads employment kingdoms Attalus Vienna \n",
      " \n",
      "epoch 0 batch# 150 batch loss: -2.3264022104285687e-05 7.6% samples processed\n",
      "question <SOS> The areas that people live in typically receive what range of kWh m2 per day <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
      "answer: 3 5 to 7 0 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
      "prediction: Hochbunker Radziwiłł Inspiration Quakers friction testosterone visited miles salute Vienna heads heads employment \n",
      " \n",
      "epoch 0 batch# 200 batch loss: -2.3330099622853595e-05 9.5% samples processed\n",
      "question <SOS> What are the four Immeasurable minds <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
      "answer: love compassion joy and equanimity <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
      "prediction: Hochbunker politician MIRV Middletown ISIS Mr Régis Cheney galactose trail trail Vienna 821 \n",
      " \n",
      "epoch 0 batch# 250 batch loss: -2.336027063165602e-05 11.4% samples processed\n",
      "question <SOS> Because of the relay issues IOC decided to no longer have what in subsequent Olympics <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
      "answer: global relays <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
      "prediction: Hochbunker erectus Bildungsroman mazurka Ominous Emperor symptom work Beacon coder heads employment heads \n",
      " \n",
      "epoch 0 batch# 300 batch loss: -2.3189904140963336e-05 13.3% samples processed\n",
      "question <SOS> What was the first institute of technology in the world <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
      "answer: the Berg Schola <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
      "prediction: Hochbunker Radziwiłł foraging adventurous adventurous Spain photomask heads heads employment ParkScore scream kitāb \n",
      " \n",
      "epoch 0 batch# 350 batch loss: -2.3288133832011226e-05 15.2% samples processed\n",
      "question <SOS> What color is the exterior of Schwarzenegger s Bugatti Veyron Grand Sport Vitesse <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
      "answer: silver <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
      "prediction: Hochbunker Grade Historic Gipper fermented XHTIT Shengzhou Theravadin ISIS Postes Metro Jaered placebo \n",
      " \n",
      "epoch 0 batch# 400 batch loss: -2.3295416667679092e-05 17.0% samples processed\n",
      "question <SOS> What do modern hunter gatherers depend on at least somewhat <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
      "answer: domesticated food <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
      "prediction: Hochbunker Radziwiłł silky Encantada Regency earls heads 143 1968 nonhomogeneous heads heads heads \n",
      " \n",
      "epoch 0 batch# 450 batch loss: -2.360849634897022e-05 18.9% samples processed\n",
      "question <SOS> How long can it take to reach the equilibrium ratio <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
      "answer: days or weeks <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
      "prediction: Hochbunker Radziwiłł silky Malthusian Site trail trail heads heads heads employment heads heads \n",
      " \n",
      "epoch 0 batch# 500 batch loss: -2.307431867620835e-05 20.8% samples processed\n",
      "question <SOS> On what day would AFL games be shown on NFL Network <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
      "answer: Friday <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
      "prediction: Hochbunker slavers Pydna intellectual heads employment heads 143 1968 nonhomogeneous graze graze heads \n",
      " \n",
      "epoch 0 batch# 550 batch loss: -2.31679557600728e-05 22.7% samples processed\n",
      "question <SOS> What was launched in 1965 by the business school at KU <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
      "answer: interdisciplinary management science graduate studies in operations research <EOS> <PAD> <PAD> <PAD> <PAD> \n",
      "prediction: Hochbunker Radziwiłł Radziwiłł Swansea flora Van passover spent pneumatic Safavid Safavid Mauchly corrective \n",
      " \n",
      "epoch 0 batch# 600 batch loss: -2.329010607127202e-05 24.6% samples processed\n",
      "question <SOS> What position in Yugoslavia s government did Tito hold from 1944 63 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
      "answer: Prime Minister <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
      "prediction: Hochbunker billiards bathrooms Byronic billiards ISIS ISIS Diocesan heads kingdoms heads heads employment \n",
      " \n",
      "epoch 0 batch# 650 batch loss: -2.3273757278730045e-05 26.5% samples processed\n",
      "question <SOS> Who controlled the inland trade in Guinea Bissau during this time <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
      "answer: local African rulers <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
      "prediction: Hochbunker Radziwiłł Radziwiłł silky Guard Cabrillo heads heads heads employment ParkScore ParkScore Dhyani \n",
      " \n",
      "epoch 0 batch# 700 batch loss: -2.3254678637840698e-05 28.4% samples processed\n",
      "question <SOS> Which kind of wood contains lignin derived from two main alcohol sources <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
      "answer: Hardwood <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
      "prediction: Hochbunker suprachiasmatic suprachiasmatic Spain pri heads employment Mengjiang Nusra ISIS graze 1863 kingdoms \n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "questions = src.utils.tokenize_questions(raw_questions, vocab_source)\n",
    "answers = src.utils.tokenize_answers(raw_answers, vocab_target)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "is_cuda = torch.cuda.is_available()\n",
    "#is_cuda = False\n",
    "print(\"is cuda:\",is_cuda)\n",
    "\n",
    "\n",
    "# hyperparams\n",
    "epochs = 100\n",
    "\n",
    "batch_size = 32\n",
    "hidden_size = 64\n",
    "lr = 0.01\n",
    "teacher_forcing_ratio = 0.5\n",
    "print_each = 100\n",
    "\n",
    "\n",
    "loader  = DataLoader(list(zip(questions, answers)), shuffle = False, batch_size = batch_size)\n",
    "\n",
    "#print(loader.shape)\n",
    "\n",
    "\n",
    "# model\n",
    "input_size = len(vocab_source.words)\n",
    "hidden_size = hidden_size\n",
    "output_size = len(vocab_target.words)\n",
    "model = Seq2Seq(input_size, hidden_size, output_size)\n",
    "\n",
    "\n",
    "if Path(\"checkpoints/model_1.pt\").is_file():\n",
    "    model.load_state_dict(torch.load(\"checkpoints/model_1.pt\"))\n",
    "    print(\"loading from checkpoint: ''checkpoints/model_1.pt'\")\n",
    "else:\n",
    "    print(\"nothing to load at checkpoint: 'checkpoints/model_1.pt'\")\n",
    "\n",
    "model.to(device)\n",
    "# training\n",
    "\n",
    "optim = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "loss_fn = nn.NLLLoss()\n",
    "model.train()\n",
    "epoch = 0\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    for batch_i, (questions, answers) in enumerate(loader):\n",
    "        batch_loss = 0\n",
    "        #outputs = []\n",
    "        for q, a in zip(questions, answers):       \n",
    "            start = next(iter(torch.LongTensor([vocab_target.words[\"<SOS>\"]])))\n",
    "            optim.zero_grad()\n",
    "            output = model(q,a,start)\n",
    "            \n",
    "            rand = random.uniform(0,1)\n",
    "            loss = loss_fn(output, a.to(device))\n",
    "            loss.backward(retain_graph=True)\n",
    "            optim.step()\n",
    "            batch_loss += loss.item()\n",
    "            #outputs.append([output])\n",
    "        if batch_i % print_each == 0:\n",
    "            share = round(((batch_i+print_each)*100)/len(loader),1)\n",
    "            print(\" \")\n",
    "            print(\"epoch\", epoch, \"batch#\",batch_i,\"batch loss:\",batch_loss/batch_size, f\"{share}% samples processed\")\n",
    "            text = \"\"\n",
    "            for x in q:\n",
    "                text += vocab_source.index[str(x.item())] + \" \"\n",
    "            print(\"question\",text)\n",
    "            text = \"\"\n",
    "            for x in a:\n",
    "                #print(x)\n",
    "                text += vocab_target.index[str(x.item())] + \" \"\n",
    "            print(\"answer:\", text)\n",
    "            text = \"\"\n",
    "            for x in output:\n",
    "                #print(x)\n",
    "                text += vocab_target.index[str(torch.argmax(x,dim=0).item())] + \" \"\n",
    "            print(\"prediction:\", text)\n",
    "        if batch_i % 200 == 0:\n",
    "            torch.save(model.state_dict(),\"checkpoints/model_1.pt\")\n",
    "                  \n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "30000/205\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_target.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pathlib import Path\n",
    "\n",
    "# questions = src.utils.tokenize_questions(questions, vocab_source)\n",
    "# answers = src.utils.tokenize_answers(answers, vocab_target)\n",
    "\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# is_cuda = torch.cuda.is_available()\n",
    "# #is_cuda = False\n",
    "# print(\"is cuda:\",is_cuda)\n",
    "\n",
    "\n",
    "# # hyperparams\n",
    "# epochs = 1\n",
    "\n",
    "# batch_size = 32\n",
    "# hidden_size = 2\n",
    "# lr = 0.01\n",
    "# teacher_forcing_ratio = 0.5\n",
    "# loader  = DataLoader(list(zip(questions, answers)), shuffle = False, batch_size = batch_size)\n",
    "# print\n",
    "\n",
    "\n",
    "# # model\n",
    "# input_size = len(vocab_source.words)\n",
    "# hidden_size = hidden_size\n",
    "# output_size = len(vocab_target.words)\n",
    "# model = Seq2Seq(input_size, hidden_size, output_size)\n",
    "\n",
    "\n",
    "# if Path(\"./checkpoints/model_1.pt\").is_file():\n",
    "#     model.load_state_dict(torch.load(\"./checkpoints/model_1.pt\"))\n",
    "#     print(\"loading from checkpoint: ''./checkpoints/model_1.pt'\")\n",
    "# else:\n",
    "#     print(\"nothing to load at checkpoint: './checkpoints/model_1.pt'\")\n",
    "\n",
    "# model.to(device)\n",
    "# # training\n",
    "\n",
    "# optim = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "# loss_fn = nn.NLLLoss()\n",
    "# model.train()\n",
    "# epoch = 0\n",
    "# for epoch in range(epochs):\n",
    "\n",
    "#     for batch_i, (questions, answers) in enumerate(loader):\n",
    "#         batch_loss = 0\n",
    "#         for q, a in zip(questions, answers):       \n",
    "#             start = next(iter(torch.LongTensor([vocab_target.words[\"<SOS>\"]])))\n",
    "#             optim.zero_grad()\n",
    "#             output = model(q,a,start)\n",
    "            \n",
    "#             rand = random.uniform(0,1)\n",
    "#             loss = loss_fn(output, a.to(device))\n",
    "#             loss.backward(retain_graph=True)\n",
    "#             optim.step()\n",
    "#             batch_loss += loss.item()\n",
    "#             #print(\"loss:\",loss.item())\n",
    "#         if batch_i % 50 == 0:\n",
    "#             share = round((batch_size * batch_i)/len(questions)*100,1)\n",
    "#             print(\"batch#\",batch_i,\"batch loss:\",batch_loss/batch_size, f\"{share}% samples processed\")\n",
    "#         if batch_i % 200 == 0:\n",
    "#             torch.save(model.state_dict(),\"./checkpoints/model_1.pt\")\n",
    "                  \n",
    "\n",
    "\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(qt)\n",
    "print(trg)\n",
    "print(hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.memory_summary(device='cuda', abbreviated=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.Tensor(2)\n",
    "#t = t.view(1,-1)\n",
    "t.shape\n",
    "t=t.view()\n",
    "t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "at = at.view(-1)\n",
    "output = output.squeeze(0)\n",
    "print(at.shape)\n",
    "print(output.shape)\n",
    "loss_fn(output,at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for que in questions[:2]:\n",
    "    for word in que:\n",
    "        print(word.shape, word.view(-1).shape,word.view(1,-1).shape,word.view(1,-1), word.view(1,1,-1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.abc\n",
    "src.abc.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "F.one_hot(torch.Tensor([19]),50)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "(Starter Code) LSTM Bot",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
