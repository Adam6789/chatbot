{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pJAWnBFlkE2w"
   },
   "source": [
    "# LSTM Bot\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "In this project, you will build a chatbot that can converse with you at the command line. The chatbot will use a Sequence to Sequence text generation architecture with an LSTM as it's memory unit. You will also learn to use pretrained word embeddings to improve the performance of the model. At the conclusion of the project, you will be able to show your chatbot to potential employers.\n",
    "\n",
    "Additionally, you have the option to use pretrained word embeddings in your model. We have loaded Brown Embeddings from Gensim in the starter code below. You can compare the performance of your model with pre-trained embeddings against a model without the embeddings.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "A sequence to sequence model (Seq2Seq) has two components:\n",
    "- An Encoder consisting of an embedding layer and LSTM unit.\n",
    "- A Decoder consisting of an embedding layer, LSTM unit, and linear output unit.\n",
    "\n",
    "The Seq2Seq model works by accepting an input into the Encoder, passing the hidden state from the Encoder to the Decoder, which the Decoder uses to output a series of token predictions.\n",
    "\n",
    "## Dependencies\n",
    "\n",
    "- Pytorch\n",
    "- Numpy\n",
    "- Pandas\n",
    "- NLTK\n",
    "- Gzip\n",
    "- Gensim\n",
    "\n",
    "\n",
    "Please choose a dataset from the Torchtext website. We recommend looking at the Squad dataset first. Here is a link to the website where you can view your options:\n",
    "\n",
    "- https://pytorch.org/text/stable/datasets.html\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = False\n",
    "init = False\n",
    "\n",
    "if test:\n",
    "    !pip install -U  pytest\n",
    "if init:\n",
    "    !pip install typing-extensions --upgrade\n",
    "    !pip install -U torch torchvision torchtext torchdata pytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# public libraries\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gzip\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import torch.optim\n",
    "import random\n",
    "\n",
    "# my libraries\n",
    "import utils\n",
    "import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eg81uNTWixbi",
    "outputId": "9c0f9eda-75fb-4526-e9b6-f9a76eeeb007"
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    from nltk.corpus import brown\n",
    "    from nltk.tokenize import RegexpTokenizer\n",
    "    import gensim\n",
    "\n",
    "\n",
    "    #from ntlk.stem import *\n",
    "\n",
    "    nltk.download('brown')\n",
    "    nltk.download('punkt')\n",
    "\n",
    "    # Output, save, and load brown embeddings\n",
    "\n",
    "    model = gensim.models.Word2Vec(brown.sents())\n",
    "    model.save('brown.embedding')\n",
    "\n",
    "    w2v = gensim.models.Word2Vec.load('brown.embedding')\n",
    "\n",
    "\n",
    "\n",
    "    def loadDF(path):\n",
    "      '''\n",
    "\n",
    "      You will use this function to load the dataset into a Pandas Dataframe for processing.\n",
    "\n",
    "      '''\n",
    "      return df\n",
    "\n",
    "\n",
    "    def prepare_text(sentence):\n",
    "\n",
    "        '''\n",
    "\n",
    "        Our text needs to be cleaned with a tokenizer. This function will perform that task.\n",
    "        https://www.nltk.org/api/nltk.tokenize.html\n",
    "\n",
    "        '''\n",
    "\n",
    "        return tokens\n",
    "\n",
    "\n",
    "\n",
    "    def train_test_split(SRC, TRG):\n",
    "\n",
    "        '''\n",
    "        Input: SRC, our list of questions from the dataset\n",
    "                TRG, our list of responses from the dataset\n",
    "\n",
    "        Output: Training and test datasets for SRC & TRG\n",
    "\n",
    "        '''\n",
    "        share = 0.2\n",
    "        src_split = len(SRC)*share\n",
    "        trg_split = len(TRG)*share\n",
    "        SRC_test_dataset = SRC[:scr_split]\n",
    "        SRC_train_dataset = SRC[scr_split:]\n",
    "        TRG_test_dataset = SRC[:trg_split]\n",
    "        TRG_train_dataset = SRC[trg_split:]\n",
    "\n",
    "\n",
    "        return SRC_train_dataset, SRC_test_dataset, TRG_train_dataset, TRG_test_dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get and watch the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87599 training samples and 10570 have been loaded.\n",
      "The test data makes 89.2% of all the data.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>answer_start</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>To whom did the Virgin Mary allegedly appear i...</td>\n",
       "      <td>['Saint Bernadette Soubirous']</td>\n",
       "      <td>[515]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What is in front of the Notre Dame Main Building?</td>\n",
       "      <td>['a copper statue of Christ']</td>\n",
       "      <td>[188]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>The Basilica of the Sacred heart at Notre Dame...</td>\n",
       "      <td>['the Main Building']</td>\n",
       "      <td>[279]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What is the Grotto at Notre Dame?</td>\n",
       "      <td>['a Marian place of prayer and reflection']</td>\n",
       "      <td>[381]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What sits on top of the Main Building at Notre...</td>\n",
       "      <td>['a golden statue of the Virgin Mary']</td>\n",
       "      <td>[92]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                            context  \\\n",
       "0           0  Architecturally, the school has a Catholic cha...   \n",
       "1           1  Architecturally, the school has a Catholic cha...   \n",
       "2           2  Architecturally, the school has a Catholic cha...   \n",
       "3           3  Architecturally, the school has a Catholic cha...   \n",
       "4           4  Architecturally, the school has a Catholic cha...   \n",
       "\n",
       "                                            question  \\\n",
       "0  To whom did the Virgin Mary allegedly appear i...   \n",
       "1  What is in front of the Notre Dame Main Building?   \n",
       "2  The Basilica of the Sacred heart at Notre Dame...   \n",
       "3                  What is the Grotto at Notre Dame?   \n",
       "4  What sits on top of the Main Building at Notre...   \n",
       "\n",
       "                                        answer answer_start  \n",
       "0               ['Saint Bernadette Soubirous']        [515]  \n",
       "1                ['a copper statue of Christ']        [188]  \n",
       "2                        ['the Main Building']        [279]  \n",
       "3  ['a Marian place of prayer and reflection']        [381]  \n",
       "4       ['a golden statue of the Virgin Mary']         [92]  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if init:\n",
    "    data.squad1_to_csv()\n",
    "    \n",
    "df_train = pd.read_csv('train_dataset_squad1.csv')  \n",
    "df_test = pd.read_csv('dev_dataset_squad1.csv') \n",
    "split = round(len(df_train)*100/(len(df_train)+len(df_test)),1)\n",
    "print(f\"{len(df_train)} training samples and {len(df_test)} have been loaded.\")\n",
    "print(f\"The test data makes {split}% of all the data.\")\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create vocabulary and dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('<PAD>', 0),\n",
       " ('<SOS>', 1),\n",
       " ('<EOS>', 2),\n",
       " ('<OUT>', 3),\n",
       " ('Saint', 4),\n",
       " ('Bernadette', 5),\n",
       " ('Soubirous', 6),\n",
       " ('To', 7)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Vocab:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.index = {}\n",
    "        self.count = 0\n",
    "        self.words = {}\n",
    "        \n",
    "    def clean_text(self, text):\n",
    "        tokenizer = RegexpTokenizer(r'\\w+')\n",
    "        text = tokenizer.tokenize(text)\n",
    "        return text\n",
    "                                    \n",
    "    def indexWord(self, word):\n",
    "        if word not in self.words:\n",
    "            self.words[word] = self.count\n",
    "            self.index[str(self.count)] = word\n",
    "            self.count += 1\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "vocab = utils.Vocab(name='SQuAD1')\n",
    "count = 0\n",
    "for i, r in df_train.iterrows():\n",
    "    question_words = vocab.clean_text(r['question'])\n",
    "    answer_words = vocab.clean_text(r['answer'][2:-2])\n",
    "    PAD = \"<PAD>\"\n",
    "    SOS = \"<SOS>\"\n",
    "    EOS = \"<EOS>\"\n",
    "    OUT = \"<OUT>\"\n",
    "    special_tokens = [\"<PAD>\", \"<SOS>\", \"<EOS>\", \"<OUT>\"]\n",
    "    for word in special_tokens + answer_words + question_words:\n",
    "        vocab.indexWord(word)\n",
    "\n",
    "VOCAB_SIZE = len(vocab.words)\n",
    "list(vocab.words.items())[:8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating sequence necessary sequence length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sequence has to have a length of 44.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>answer_start</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>To whom did the Virgin Mary allegedly appear i...</td>\n",
       "      <td>['Saint Bernadette Soubirous']</td>\n",
       "      <td>[515]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What is in front of the Notre Dame Main Building?</td>\n",
       "      <td>['a copper statue of Christ']</td>\n",
       "      <td>[188]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>The Basilica of the Sacred heart at Notre Dame...</td>\n",
       "      <td>['the Main Building']</td>\n",
       "      <td>[279]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What is the Grotto at Notre Dame?</td>\n",
       "      <td>['a Marian place of prayer and reflection']</td>\n",
       "      <td>[381]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What sits on top of the Main Building at Notre...</td>\n",
       "      <td>['a golden statue of the Virgin Mary']</td>\n",
       "      <td>[92]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                            context  \\\n",
       "0           0  Architecturally, the school has a Catholic cha...   \n",
       "1           1  Architecturally, the school has a Catholic cha...   \n",
       "2           2  Architecturally, the school has a Catholic cha...   \n",
       "3           3  Architecturally, the school has a Catholic cha...   \n",
       "4           4  Architecturally, the school has a Catholic cha...   \n",
       "\n",
       "                                            question  \\\n",
       "0  To whom did the Virgin Mary allegedly appear i...   \n",
       "1  What is in front of the Notre Dame Main Building?   \n",
       "2  The Basilica of the Sacred heart at Notre Dame...   \n",
       "3                  What is the Grotto at Notre Dame?   \n",
       "4  What sits on top of the Main Building at Notre...   \n",
       "\n",
       "                                        answer answer_start  \n",
       "0               ['Saint Bernadette Soubirous']        [515]  \n",
       "1                ['a copper statue of Christ']        [188]  \n",
       "2                        ['the Main Building']        [279]  \n",
       "3  ['a Marian place of prayer and reflection']        [381]  \n",
       "4       ['a golden statue of the Virgin Mary']         [92]  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_length = utils.get_sequence_length(df_train, vocab)\n",
    "print(f\"The sequence has to have a length of {sequence_length}.\")\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if test:\n",
    "    !python -m pytest -vv tests.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "oQLTP2Wmi1eB"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class Encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, embedding_size, hidden_size):\n",
    "        \n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        # self.embedding provides a vector representation of the inputs to our model\n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "        \n",
    "        # self.lstm, accepts the vectorized input and passes a hidden state\n",
    "        self.lstm = nn.LSTM(embedding_size, hidden_size)\n",
    "        self.dropout = nn.Dropout(p=0.0)\n",
    "        \n",
    "    \n",
    "    def forward(self, i, h):\n",
    "        \n",
    "        '''\n",
    "        Inputs: i, the src vector\n",
    "        Outputs: o, the encoder outputs\n",
    "                h, the hidden state\n",
    "                c, the cell state\n",
    "        '''\n",
    "        embedding = self.embedding(i)\n",
    "\n",
    "        o, h= self.lstm(embedding, h)\n",
    "        o = self.dropout(o)\n",
    "        \n",
    "        return o, h\n",
    "    \n",
    "\n",
    "class Decoder(nn.Module):\n",
    "      \n",
    "    def __init__(self, hidden_size, embedding_size, output_size):\n",
    "        \n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        # self.embedding provides a vector representation of the target to our model\n",
    "        self.embedding = nn.Embedding(output_size, embedding_size)\n",
    "        \n",
    "        # self.lstm, accepts the embeddings and outputs a hidden state\n",
    "        self.lstm = nn.LSTM(embedding_size, hidden_size)\n",
    "\n",
    "        # self.ouput, predicts on the hidden state via a linear output layer  \n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, i, h):\n",
    "        \n",
    "        '''\n",
    "        Inputs: i, the target vector\n",
    "        Outputs: o, the prediction\n",
    "                h, the hidden state (actually a tuple of hidden state and cell state)\n",
    "        '''\n",
    "\n",
    "        embedding = self.embedding(i)\n",
    "\n",
    "        o, h = self.lstm(embedding, h)\n",
    "\n",
    "        o = self.linear(o)\n",
    "\n",
    "        o = self.softmax(o)\n",
    "\n",
    "        \n",
    "        return o, h\n",
    "        \n",
    "        \n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    \n",
    "    def __init__(self, encoder_input_size, embedding_size, hidden_size, decoder_output_size):\n",
    "        \n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = Encoder(encoder_input_size, embedding_size, hidden_size)\n",
    "        self.decoder = Decoder(hidden_size, embedding_size, decoder_output_size)\n",
    "                \n",
    "        \n",
    "    \n",
    "    \n",
    "    def forward(self, src, trg, he, teacher_forcing_ratio = 0.5): \n",
    "        o, he = self.encoder(src, he)\n",
    "        o, hd = self.decoder(trg, he)\n",
    "        \n",
    "        \n",
    "        return o, he\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = utils.get_questions(df_train, vocab)\n",
    "answers = utils.get_answers(df_train, vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# encoder_input_size = 4\n",
    "# embedding_size = 2\n",
    "\n",
    "# hidden_size = 3\n",
    "# decoder_output_size = 4\n",
    "# print(encoder_input_size, embedding_size, hidden_size, decoder_output_size)\n",
    "# qt=torch.LongTensor([[1]])\n",
    "# trg=torch.LongTensor([[0]])\n",
    "# hidden=torch.zeros(1,1,hidden_size)\n",
    "# hidden = (hidden, hidden)\n",
    "# # 1.\n",
    "# e = nn.Embedding(encoder_input_size, embedding_size)\n",
    "# embedding = e(qt)\n",
    "# #print(embedding.shape, hidden.shape)\n",
    "# #print(embedding)\n",
    "# # 2.\n",
    "# lstm = nn.LSTM(embedding_size, hidden_size,1)\n",
    "\n",
    "# lstm(embedding, hidden)\n",
    "# lstm\n",
    "\n",
    "# model = Seq2Seq(encoder_input_size, embedding_size, hidden_size, decoder_output_size)\n",
    "# model(qt,trg,hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "hyperparams 60311 60311 10 60311\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 13.55 GiB (GPU 0; 11.17 GiB total capacity; 0 bytes already allocated; 11.12 GiB free; 0 bytes reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-6c821c3282d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSeq2Seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_input_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_output_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_cuda\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0moptim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mloss_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNLLLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    686\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m         \"\"\"\n\u001b[0;32m--> 688\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mxpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 578\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 578\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    599\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 601\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    602\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    686\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m         \"\"\"\n\u001b[0;32m--> 688\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mxpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 13.55 GiB (GPU 0; 11.17 GiB total capacity; 0 bytes already allocated; 11.12 GiB free; 0 bytes reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "is_cuda = torch.cuda.is_available()\n",
    "#is_cuda = False\n",
    "print(is_cuda)\n",
    "\n",
    "import torch.optim\n",
    "# hyperparams\n",
    "epochs = 1\n",
    "batch_size = len(df_train)\n",
    "batch_size = 10\n",
    "hidden_size = 10\n",
    "lr = 0.01\n",
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "\n",
    "# model\n",
    "encoder_input_size = len(vocab.words)\n",
    "embedding_size = len(vocab.words)\n",
    "hidden_size = hidden_size\n",
    "decoder_output_size = len(vocab.words)\n",
    "print(\"hyperparams\", encoder_input_size, embedding_size, hidden_size, decoder_output_size)\n",
    "\n",
    "\n",
    "model = Seq2Seq(encoder_input_size, embedding_size, hidden_size, decoder_output_size)\n",
    "if is_cuda:\n",
    "    model.cuda()\n",
    "optim = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "loss_fn = nn.NLLLoss()\n",
    "\n",
    "\n",
    "# training\n",
    "batches = len(df_train)//batch_size\n",
    "epoch = 0\n",
    "for epoch in range(epochs):\n",
    "    hidden = (torch.zeros(1,hidden_size), torch.zeros(1,hidden_size))\n",
    "    for batch in range(batches):\n",
    "                   \n",
    "        for q, a in zip(questions[:10], answers[:10]):\n",
    "            # trg: created target/answer\n",
    "            # at: \"true\" target/answer\n",
    "            # qt: input source/question\n",
    "            trg = torch.LongTensor([vocab.words[\"<SOS>\"]])\n",
    "            print(trg, trg.shape)\n",
    "\n",
    "            for qt, at in zip(q, a):\n",
    "                qt = qt.view(-1)\n",
    "                at = at.view(-1)\n",
    "                \n",
    "                optim.zero_grad() \n",
    "                if is_cuda:\n",
    "                    at=at.cuda()\n",
    "                    qt=qt.cuda()\n",
    "                    trg=trg.cuda()\n",
    "                    a,b=hidden\n",
    "                    hidden = a.cuda(),b.cuda()\n",
    "                output, hidden = model(qt, trg, hidden)\n",
    "\n",
    "\n",
    "                a,b = hidden\n",
    "         \n",
    "                rand = random.uniform(0,1)\n",
    "                if rand > teacher_forcing_ratio:\n",
    "                    loss = loss_fn(output, at)\n",
    "                else:\n",
    "                    loss = loss_fn(output, trg)\n",
    "\n",
    "                loss.backward()\n",
    "                optim.step()\n",
    "                \n",
    "                print(\"loss\",loss)\n",
    "                trg = output\n",
    "                print(\"###\")\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(qt)\n",
    "print(trg)\n",
    "print(hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.memory_summary(device='cuda', abbreviated=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.Tensor(2)\n",
    "#t = t.view(1,-1)\n",
    "t.shape\n",
    "t=t.view()\n",
    "t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "at = at.view(-1)\n",
    "output = output.squeeze(0)\n",
    "print(at.shape)\n",
    "print(output.shape)\n",
    "loss_fn(output,at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is_cuda = torch.cuda.is_available()\n",
    "# print(is_cuda)\n",
    "\n",
    "# import torch.optim\n",
    "# # hyperparams\n",
    "# epochs = 1\n",
    "# batch_size = len(df_train)\n",
    "# batch_size = 10\n",
    "# hidden_size = 100\n",
    "# lr = 0.01\n",
    "# teacher_forcing_ratio = 0.5\n",
    "\n",
    "\n",
    "# # model\n",
    "# encoder_input_size = len(vocab.words)\n",
    "# embedding_size = len(vocab.words)\n",
    "# hidden_size = hidden_size\n",
    "# decoder_output_size = len(vocab.words)\n",
    "# print(encoder_input_size, embedding_size, hidden_size, decoder_output_size)\n",
    "\n",
    "\n",
    "# model = Seq2Seq(encoder_input_size, embedding_size, hidden_size, decoder_output_size)\n",
    "# if is_cuda:\n",
    "#     model.cuda()\n",
    "# optim = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "# loss_fn = nn.NLLLoss()\n",
    "\n",
    "\n",
    "# # training\n",
    "# batches = len(df_train)//batch_size\n",
    "# epoch = 0\n",
    "# for epoch in range(epochs):\n",
    "#     hidden = (torch.zeros(1,1,hidden_size), torch.zeros(1,1,hidden_size))\n",
    "#     for batch in range(batches):\n",
    "                   \n",
    "#         for q, a in zip(questions[:10], answers[:10]):\n",
    "#             trg = torch.LongTensor([[vocab.words[\"<SOS>\"]]])\n",
    "#             print(trg, trg.shape)\n",
    "\n",
    "#             for qt, at in zip(q, a):\n",
    "                \n",
    "#                 optim.zero_grad() \n",
    "#                 at = at.view(1,-1)\n",
    "#                 qt = qt.view(1,-1)\n",
    "#                 if is_cuda:\n",
    "#                     at=at.cuda()\n",
    "#                     qt=qt.cuda()\n",
    "#                     trg=trg.cuda()\n",
    "#                     a,b=hidden\n",
    "#                     hidden = a.cuda(),b.cuda()\n",
    "#                 print(\"trg\", trg.shape)\n",
    "#                 print(\"at\", at.shape)\n",
    "#                 output, hidden = model(qt, trg, hidden)\n",
    "\n",
    "\n",
    "#                 a,b = hidden\n",
    "#                 print(output.shape, at.shape)\n",
    "#                 print(output, at)\n",
    "                \n",
    "#                 rand = random.uniform(0,1)\n",
    "#                 if rand > teacher_forcing_ratio:\n",
    "#                     loss = loss_fn(output, at)\n",
    "#                 else:\n",
    "#                     loss = loss_fn(output, trg)\n",
    "#                 loss.backward()\n",
    "#                 trg = output\n",
    "#                 print(\"###\")\n",
    "            \n",
    "            \n",
    "            \n",
    "#         break\n",
    "#     break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for que in questions[:2]:\n",
    "    for word in que:\n",
    "        print(word.shape, word.view(-1).shape,word.view(1,-1).shape,word.view(1,-1), word.view(1,1,-1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.abc\n",
    "src.abc.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "F.one_hot(torch.Tensor([19]),50)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "(Starter Code) LSTM Bot",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
